{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9143c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using K-Means clustering to build a product recommendation system from two different datasets\n",
    "#one dataset has movies and the other has ratings made by users that have watched the movie; common field is movie_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7af2c0ec-9f4d-48df-bc6b-ff9eb4a8d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('C:\\Input\\ml-latest-small.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce292c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "import pandas as pd\n",
    "movies_df = pd.read_csv('data/ml-latest-small/movies.csv')\n",
    "ratings_df = pd.read_csv('data/ml-latest-small/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a311d7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      " 10  955k   10   99k    0     0  47622      0  0:00:20  0:00:02  0:00:18 47631\n",
      " 41  955k   41  400k    0     0   118k      0  0:00:08  0:00:03  0:00:05  118k\n",
      " 73  955k   73  698k    0     0   164k      0  0:00:05  0:00:04  0:00:01  164k\n",
      " 99  955k   99  955k    0     0   183k      0  0:00:05  0:00:05 --:--:--  187k\n",
      "100  955k  100  955k    0     0   177k      0  0:00:05  0:00:05 --:--:--  261k\n"
     ]
    }
   ],
   "source": [
    "# Data Citation:\n",
    "# F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on \n",
    "# Interactive Intelligent Systems (TiiS) 5, 4: 19:1–19:19. <https://doi.org/10.1145/2827872>\n",
    "\n",
    "! curl http://files.grouplens.org/datasets/movielens/ml-latest-small.zip -o ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "889f5571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of movies dataframe are: (9742, 3) \n",
      "The dimensions of ratings dataframe are: (100836, 4)\n"
     ]
    }
   ],
   "source": [
    "print('The dimensions of movies dataframe are:', movies_df.shape,'\\nThe dimensions of ratings dataframe are:', ratings_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee452c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at movies_df\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3ef0176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at ratings_df\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6a92959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 610\n",
      "Number of unique movies: 9724\n",
      "The full rating matrix will have: 5931640 elements.\n",
      "----------\n",
      "Number of ratings: 100836\n",
      "Therefore:  1.6999683055613624 % of the matrix is filled.\n",
      "We have an incredibly sparse matrix to work with here.\n",
      "And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\n",
      "You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\n",
      "One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\n"
     ]
    }
   ],
   "source": [
    "# Movie ID to movie name mapping\n",
    "movie_names = movies_df.set_index('movieId')['title'].to_dict()\n",
    "n_users = len(ratings_df.userId.unique())\n",
    "n_items = len(ratings_df.movieId.unique())\n",
    "print(\"Number of unique users:\", n_users)\n",
    "print(\"Number of unique movies:\", n_items)\n",
    "print(\"The full rating matrix will have:\", n_users*n_items, 'elements.')\n",
    "print('----------')\n",
    "print(\"Number of ratings:\", len(ratings_df))\n",
    "print(\"Therefore: \", len(ratings_df) / (n_users*n_items) * 100, '% of the matrix is filled.')\n",
    "print(\"We have an incredibly sparse matrix to work with here.\")\n",
    "print(\"And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\")\n",
    "print(\"You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\")\n",
    "print(\"One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d689a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        # create user embeddings\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors) # think of this as a lookup table for the input.\n",
    "        # create item embeddings\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors) # think of this as a lookup table for the input.\n",
    "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
    "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # matrix multiplication\n",
    "        users, items = data[:,0], data[:,1]\n",
    "        return (self.user_factors(users)*self.item_factors(items)).sum(1)\n",
    "    # def forward(self, user, item):\n",
    "    # \t# matrix multiplication\n",
    "    #     return (self.user_factors(user)*self.item_factors(item)).sum(1)\n",
    "    \n",
    "    def predict(self, user, item):\n",
    "        return self.forward(user, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39db6b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataloader (necessary for PyTorch)\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader # package that helps transform your data to machine learning readiness\n",
    "\n",
    "# Note: This isn't 'good' practice, in a MLops sense but we'll roll with this since the data is already loaded in memory.\n",
    "class Loader(Dataset):\n",
    "    def __init__(self):\n",
    "        self.ratings = ratings_df.copy()\n",
    "        \n",
    "        # Extract all user IDs and movie IDs\n",
    "        users = ratings_df.userId.unique()\n",
    "        movies = ratings_df.movieId.unique()\n",
    "        \n",
    "        #--- Producing new continuous IDs for users and movies ---\n",
    "        \n",
    "        # Unique values : index\n",
    "        self.userid2idx = {o:i for i,o in enumerate(users)}\n",
    "        self.movieid2idx = {o:i for i,o in enumerate(movies)}\n",
    "        \n",
    "        # Obtained continuous ID for users and movies\n",
    "        self.idx2userid = {i:o for o,i in self.userid2idx.items()}\n",
    "        self.idx2movieid = {i:o for o,i in self.movieid2idx.items()}\n",
    "        \n",
    "        # return the id from the indexed values as noted in the lambda function down below.\n",
    "        self.ratings.movieId = ratings_df.movieId.apply(lambda x: self.movieid2idx[x])\n",
    "        self.ratings.userId = ratings_df.userId.apply(lambda x: self.userid2idx[x])\n",
    "        \n",
    "        \n",
    "        self.x = self.ratings.drop(['rating', 'timestamp'], axis=1).values\n",
    "        self.y = self.ratings['rating'].values\n",
    "        self.x, self.y = torch.tensor(self.x), torch.tensor(self.y) # Transforms the data to tensors (ready for torch models.)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c7bf440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is running on GPU: False\n",
      "MatrixFactorization(\n",
      "  (user_factors): Embedding(610, 8)\n",
      "  (item_factors): Embedding(9724, 8)\n",
      ")\n",
      "user_factors.weight tensor([[0.0241, 0.0197, 0.0420,  ..., 0.0419, 0.0218, 0.0357],\n",
      "        [0.0082, 0.0418, 0.0145,  ..., 0.0374, 0.0165, 0.0463],\n",
      "        [0.0085, 0.0138, 0.0077,  ..., 0.0012, 0.0327, 0.0059],\n",
      "        ...,\n",
      "        [0.0014, 0.0158, 0.0446,  ..., 0.0152, 0.0148, 0.0178],\n",
      "        [0.0345, 0.0120, 0.0185,  ..., 0.0265, 0.0124, 0.0142],\n",
      "        [0.0333, 0.0227, 0.0442,  ..., 0.0463, 0.0087, 0.0314]])\n",
      "item_factors.weight tensor([[0.0325, 0.0448, 0.0164,  ..., 0.0266, 0.0104, 0.0189],\n",
      "        [0.0272, 0.0062, 0.0381,  ..., 0.0336, 0.0042, 0.0316],\n",
      "        [0.0139, 0.0295, 0.0290,  ..., 0.0441, 0.0418, 0.0144],\n",
      "        ...,\n",
      "        [0.0106, 0.0417, 0.0480,  ..., 0.0392, 0.0218, 0.0049],\n",
      "        [0.0022, 0.0127, 0.0481,  ..., 0.0393, 0.0297, 0.0212],\n",
      "        [0.0112, 0.0262, 0.0388,  ..., 0.0221, 0.0001, 0.0263]])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 128\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Is running on GPU:\", cuda)\n",
    "\n",
    "model = MatrixFactorization(n_users, n_items, n_factors=8)\n",
    "print(model)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "# GPU enable if you have a GPU...\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# MSE loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# ADAM optimizier\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train data\n",
    "train_set = Loader()\n",
    "train_loader = DataLoader(train_set, 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12e9d749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-dad152416852>:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for it in tqdm(range(num_epochs)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e787caee074db895c950d4d140ac69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-dad152416852>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"iter #{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Loss:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "for it in tqdm(range(num_epochs)):\n",
    "    losses = []\n",
    "    for x, y in train_loader:\n",
    "         if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = loss_fn(outputs.squeeze(), y.type(torch.float32))\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18aead44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_factors.weight tensor([[0.0241, 0.0197, 0.0420,  ..., 0.0419, 0.0218, 0.0357],\n",
      "        [0.0082, 0.0418, 0.0145,  ..., 0.0374, 0.0165, 0.0463],\n",
      "        [0.0085, 0.0138, 0.0077,  ..., 0.0012, 0.0327, 0.0059],\n",
      "        ...,\n",
      "        [0.0014, 0.0158, 0.0446,  ..., 0.0152, 0.0148, 0.0178],\n",
      "        [0.0345, 0.0120, 0.0185,  ..., 0.0265, 0.0124, 0.0142],\n",
      "        [0.0333, 0.0227, 0.0442,  ..., 0.0463, 0.0087, 0.0314]])\n",
      "item_factors.weight tensor([[0.0325, 0.0448, 0.0164,  ..., 0.0266, 0.0104, 0.0189],\n",
      "        [0.0272, 0.0062, 0.0381,  ..., 0.0336, 0.0042, 0.0316],\n",
      "        [0.0139, 0.0295, 0.0290,  ..., 0.0441, 0.0418, 0.0144],\n",
      "        ...,\n",
      "        [0.0106, 0.0417, 0.0480,  ..., 0.0392, 0.0218, 0.0049],\n",
      "        [0.0022, 0.0127, 0.0481,  ..., 0.0393, 0.0297, 0.0212],\n",
      "        [0.0112, 0.0262, 0.0388,  ..., 0.0221, 0.0001, 0.0263]])\n"
     ]
    }
   ],
   "source": [
    "# By training the model, we will have tuned latent factors for movies and users.\n",
    "c = 0\n",
    "uw = 0\n",
    "iw = 0 \n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        if c == 0:\n",
    "          uw = param.data\n",
    "          c +=1\n",
    "        else:\n",
    "          iw = param.data\n",
    "        #print('param_data', param_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe2750b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_movie_embeddings = model.item_factors.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19e37398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9724"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trained_movie_embeddings) # unique movie factor weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c3cccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Fit the clusters based on the movie weights\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb8c8b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster #0\n",
      "\t American Beauty (1999)\n",
      "\t Lord of the Rings: The Return of the King, The (2003)\n",
      "\t Gladiator (2000)\n",
      "\t Mask, The (1994)\n",
      "\t Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "\t Die Hard (1988)\n",
      "\t Pretty Woman (1990)\n",
      "\t Léon: The Professional (a.k.a. The Professional) (Léon) (1994)\n",
      "\t Kill Bill: Vol. 1 (2003)\n",
      "\t Ferris Bueller's Day Off (1986)\n",
      "Cluster #1\n",
      "\t Pulp Fiction (1994)\n",
      "\t Matrix, The (1999)\n",
      "\t Braveheart (1995)\n",
      "\t Independence Day (a.k.a. ID4) (1996)\n",
      "\t Aladdin (1992)\n",
      "\t Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
      "\t Speed (1994)\n",
      "\t Monsters, Inc. (2001)\n",
      "\t Goodfellas (1990)\n",
      "\t Blade Runner (1982)\n",
      "Cluster #2\n",
      "\t Forrest Gump (1994)\n",
      "\t Schindler's List (1993)\n",
      "\t Godfather, The (1972)\n",
      "\t Fargo (1996)\n",
      "\t Dark Knight, The (2008)\n",
      "\t Die Hard: With a Vengeance (1995)\n",
      "\t Stargate (1994)\n",
      "\t Dumb & Dumber (Dumb and Dumber) (1994)\n",
      "\t X-Men (2000)\n",
      "\t Terminator, The (1984)\n",
      "Cluster #3\n",
      "\t Back to the Future (1985)\n",
      "\t Men in Black (a.k.a. MIB) (1997)\n",
      "\t Memento (2000)\n",
      "\t Indiana Jones and the Last Crusade (1989)\n",
      "\t One Flew Over the Cuckoo's Nest (1975)\n",
      "\t Aliens (1986)\n",
      "\t Truman Show, The (1998)\n",
      "\t Incredibles, The (2004)\n",
      "\t Twister (1996)\n",
      "\t Beautiful Mind, A (2001)\n",
      "Cluster #4\n",
      "\t Fight Club (1999)\n",
      "\t Apollo 13 (1995)\n",
      "\t Dances with Wolves (1990)\n",
      "\t Princess Bride, The (1987)\n",
      "\t Batman Forever (1995)\n",
      "\t Monty Python and the Holy Grail (1975)\n",
      "\t Eternal Sunshine of the Spotless Mind (2004)\n",
      "\t Rock, The (1996)\n",
      "\t Home Alone (1990)\n",
      "\t Net, The (1995)\n",
      "Cluster #5\n",
      "\t Jurassic Park (1993)\n",
      "\t Usual Suspects, The (1995)\n",
      "\t Seven (a.k.a. Se7en) (1995)\n",
      "\t Lord of the Rings: The Two Towers, The (2002)\n",
      "\t Mrs. Doubtfire (1993)\n",
      "\t Finding Nemo (2003)\n",
      "\t Titanic (1997)\n",
      "\t Babe (1995)\n",
      "\t Catch Me If You Can (2002)\n",
      "\t Bourne Identity, The (2002)\n",
      "Cluster #6\n",
      "\t Star Wars: Episode IV - A New Hope (1977)\n",
      "\t Lord of the Rings: The Fellowship of the Ring, The (2001)\n",
      "\t Batman (1989)\n",
      "\t True Lies (1994)\n",
      "\t Alien (1979)\n",
      "\t Beauty and the Beast (1991)\n",
      "\t Groundhog Day (1993)\n",
      "\t Clueless (1995)\n",
      "\t Taxi Driver (1976)\n",
      "\t Heat (1995)\n",
      "Cluster #7\n",
      "\t Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "\t Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
      "\t Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "\t Saving Private Ryan (1998)\n",
      "\t Lion King, The (1994)\n",
      "\t Shrek (2001)\n",
      "\t Reservoir Dogs (1992)\n",
      "\t Austin Powers: The Spy Who Shagged Me (1999)\n",
      "\t Minority Report (2002)\n",
      "\t Sleepless in Seattle (1993)\n",
      "Cluster #8\n",
      "\t Shawshank Redemption, The (1994)\n",
      "\t Ace Ventura: Pet Detective (1994)\n",
      "\t E.T. the Extra-Terrestrial (1982)\n",
      "\t Ocean's Eleven (2001)\n",
      "\t Fifth Element, The (1997)\n",
      "\t Jumanji (1995)\n",
      "\t There's Something About Mary (1998)\n",
      "\t Nightmare Before Christmas, The (1993)\n",
      "\t Natural Born Killers (1994)\n",
      "\t Shakespeare in Love (1998)\n",
      "Cluster #9\n",
      "\t Silence of the Lambs, The (1991)\n",
      "\t Terminator 2: Judgment Day (1991)\n",
      "\t Toy Story (1995)\n",
      "\t Fugitive, The (1993)\n",
      "\t Sixth Sense, The (1999)\n",
      "\t Mission: Impossible (1996)\n",
      "\t Inception (2010)\n",
      "\t Good Will Hunting (1997)\n",
      "\t Star Wars: Episode I - The Phantom Menace (1999)\n",
      "\t GoldenEye (1995)\n"
     ]
    }
   ],
   "source": [
    "'''It can be seen here that the movies that are in the same cluster tend to have\n",
    "similar genres. Also note that the algorithm is unfamiliar with the movie name\n",
    "and only obtained the relationships by looking at the numbers representing how\n",
    "users have responded to the movie selections.'''\n",
    "for cluster in range(10):\n",
    "  print(\"Cluster #{}\".format(cluster))\n",
    "  movs = []\n",
    "  for movidx in np.where(kmeans.labels_ == cluster)[0]:\n",
    "    movid = train_set.idx2movieid[movidx]\n",
    "    rat_count = ratings_df.loc[ratings_df['movieId']==movid].count()[0]\n",
    "    movs.append((movie_names[movid], rat_count))\n",
    "  for mov in sorted(movs, key=lambda tup: tup[1], reverse=True)[:10]:\n",
    "    print(\"\\t\", mov[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1afc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
